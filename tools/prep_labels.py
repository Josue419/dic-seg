"""
ä¸€æ¬¡æ€§æ ‡ç­¾é¢„å¤„ç†è„šæœ¬ - ä¿®å¤æ ‡ç­¾å€¼å¹¶å­˜å‚¨åˆ°å•ç‹¬ç›®å½•

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ Cityscapes å’Œ ACDC æ ‡ç­¾çš„æœ‰æ•ˆæ€§
2. å°†é 0-18 çš„æ ‡ç­¾å€¼è½¬ä¸º 255ï¼ˆignore_indexï¼‰
3. å­˜å‚¨åˆ° .processed_labels ç›®å½•ï¼Œä¿æŒåŸæ–‡ä»¶ä¸å˜
4. ç”Ÿæˆé¢„å¤„ç†å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
"""

import argparse
import json
import time
import hashlib
from pathlib import Path
import numpy as np
from PIL import Image
from tqdm import tqdm
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class LabelPreprocessor:
    """æ ‡ç­¾é¢„å¤„ç†å™¨ - åˆ†ç¦»å­˜å‚¨æ–¹æ¡ˆ"""
    
    def __init__(self, dataset_root: Path):
        self.dataset_root = Path(dataset_root)
        self.processed_root = self.dataset_root / '.processed_labels'
        self.processed_root.mkdir(exist_ok=True)
        
        self.metadata_file = self.processed_root / 'preprocessing_metadata.json'
    
    def create_dataset_fingerprint(self) -> str:
        """åˆ›å»ºæ•°æ®é›†æŒ‡çº¹ï¼Œæ£€æµ‹æ˜¯å¦éœ€è¦é‡æ–°é¢„å¤„ç†"""
        label_files = list(self.dataset_root.rglob('*_labelIds.png'))[:100]  # é‡‡æ ·å‰100ä¸ª
        fingerprint_data = []
        
        for file_path in sorted(label_files):
            if file_path.exists():
                stat = file_path.stat()
                fingerprint_data.append(f"{file_path.name}:{stat.st_size}:{stat.st_mtime}")
        
        return hashlib.md5(''.join(fingerprint_data).encode()).hexdigest()
    
    def get_processed_label_path(self, original_path: Path) -> Path:
        """è·å–é¢„å¤„ç†åæ ‡ç­¾æ–‡ä»¶çš„å­˜å‚¨è·¯å¾„"""
        try:
            rel_path = original_path.relative_to(self.dataset_root)
        except ValueError:
            rel_path = Path(original_path.name)
        
        processed_path = self.processed_root / rel_path
        processed_path.parent.mkdir(parents=True, exist_ok=True)
        
        return processed_path
    
    def is_processed(self, original_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²è¢«é¢„å¤„ç†"""
        processed_path = self.get_processed_label_path(original_path)
        
        if not processed_path.exists():
            return False
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ¯”åŸæ–‡ä»¶æ–°
        try:
            original_mtime = original_path.stat().st_mtime
            processed_mtime = processed_path.stat().st_mtime
            return processed_mtime >= original_mtime
        except:
            return False
    
    def preprocess_label_file(self, original_path: Path) -> Path:
        """é¢„å¤„ç†å•ä¸ªæ ‡ç­¾æ–‡ä»¶"""
        
        if self.is_processed(original_path):
            return self.get_processed_label_path(original_path)
        
        # åŠ è½½åŸå§‹æ ‡ç­¾
        label_img = Image.open(original_path)
        label_array = np.array(label_img)
        
        # æ£€æŸ¥å¹¶ä¿®å¤æ ‡ç­¾å€¼
        unique_values = np.unique(label_array)
        valid_labels = set(range(19)) | {255}
        invalid_labels = set(unique_values) - valid_labels
        
        if invalid_labels:
            logger.info(f"ğŸ”§ å¤„ç† {original_path.name}: ä¿®å¤ {len(invalid_labels)} ä¸ªæ— æ•ˆæ ‡ç­¾")
            
            # ä¿®å¤æ— æ•ˆæ ‡ç­¾
            corrected_array = label_array.copy()
            for invalid_val in invalid_labels:
                corrected_array[label_array == invalid_val] = 255
        else:
            corrected_array = label_array
        
        # ä¿å­˜åˆ°å¤„ç†åçš„è·¯å¾„
        processed_path = self.get_processed_label_path(original_path)
        corrected_img = Image.fromarray(corrected_array.astype(np.uint8), mode='L')
        corrected_img.save(processed_path)
        
        return processed_path
    
    def batch_preprocess_cityscapes(self):
        """æ‰¹é‡é¢„å¤„ç† Cityscapes æ ‡ç­¾"""
        label_files = []
        for split in ['train', 'val', 'test']:
            split_dir = self.dataset_root / 'gtFine' / split
            if split_dir.exists():
                label_files.extend(list(split_dir.rglob('*_gtFine_labelIds.png')))
        
        return self._process_files(label_files, "Cityscapes")
    
    def batch_preprocess_acdc(self):
        """æ‰¹é‡é¢„å¤„ç† ACDC æ ‡ç­¾"""
        label_files = []
        for weather in ['fog', 'night', 'rain', 'snow']:
            for split in ['train', 'val']:
                split_dir = self.dataset_root / 'gt' / weather / split
                if split_dir.exists():
                    label_files.extend(list(split_dir.rglob('*_gt_labelIds.png')))
        
        return self._process_files(label_files, "ACDC")
    
    def _process_files(self, label_files: list, dataset_name: str):
        """å¤„ç†æ–‡ä»¶åˆ—è¡¨"""
        logger.info(f"æ‰¾åˆ° {len(label_files)} ä¸ª {dataset_name} æ ‡ç­¾æ–‡ä»¶")
        
        stats = {
            'dataset_name': dataset_name,
            'total_files': len(label_files),
            'processed_files': 0,
            'skipped_files': 0,
            'invalid_labels_found': set(),
            'errors': 0,
            'fingerprint': self.create_dataset_fingerprint(),
            'timestamp': time.time()
        }
        
        for label_file in tqdm(label_files, desc=f"é¢„å¤„ç† {dataset_name} æ ‡ç­¾"):
            try:
                if self.is_processed(label_file):
                    stats['skipped_files'] += 1
                    continue
                
                self.preprocess_label_file(label_file)
                stats['processed_files'] += 1
                
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥ {label_file}: {e}")
                stats['errors'] += 1
        
        # ä¿å­˜å…ƒæ•°æ®
        stats['invalid_labels_found'] = list(stats['invalid_labels_found'])
        self._save_metadata(stats)
        
        return stats
    
    def _save_metadata(self, stats: dict):
        """ä¿å­˜é¢„å¤„ç†å…ƒæ•°æ®"""
        metadata = {
            'dataset_root': str(self.dataset_root),
            'processed_root': str(self.processed_root),
            'stats': stats,
        }
        
        with open(self.metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)


def preprocess_cityscapes(data_root: Path, force: bool = False):
    """é¢„å¤„ç† Cityscapes æ•°æ®é›†"""
    preprocessor = LabelPreprocessor(data_root)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†
    if not force and preprocessor.metadata_file.exists():
        try:
            with open(preprocessor.metadata_file, 'r') as f:
                metadata = json.load(f)
            
            current_fingerprint = preprocessor.create_dataset_fingerprint()
            if metadata.get('stats', {}).get('fingerprint') == current_fingerprint:
                logger.info("âœ… Cityscapes æ•°æ®é›†å·²ç»é¢„å¤„ç†è¿‡ï¼Œè·³è¿‡")
                return metadata['stats']
        except:
            pass
    
    logger.info("ğŸ”„ å¼€å§‹é¢„å¤„ç† Cityscapes æ•°æ®é›†...")
    stats = preprocessor.batch_preprocess_cityscapes()
    
    logger.info(f"âœ… Cityscapes é¢„å¤„ç†å®Œæˆ:")
    logger.info(f"   æ€»æ–‡ä»¶: {stats['total_files']}")
    logger.info(f"   å¤„ç†æ–‡ä»¶: {stats['processed_files']}")
    logger.info(f"   è·³è¿‡æ–‡ä»¶: {stats['skipped_files']}")
    logger.info(f"   é”™è¯¯: {stats['errors']}")
    
    return stats


def preprocess_acdc(data_root: Path, force: bool = False):
    """é¢„å¤„ç† ACDC æ•°æ®é›†"""
    preprocessor = LabelPreprocessor(data_root)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†
    if not force and preprocessor.metadata_file.exists():
        try:
            with open(preprocessor.metadata_file, 'r') as f:
                metadata = json.load(f)
            
            current_fingerprint = preprocessor.create_dataset_fingerprint()
            if metadata.get('stats', {}).get('fingerprint') == current_fingerprint:
                logger.info("âœ… ACDC æ•°æ®é›†å·²ç»é¢„å¤„ç†è¿‡ï¼Œè·³è¿‡")
                return metadata['stats']
        except:
            pass
    
    logger.info("ğŸ”„ å¼€å§‹é¢„å¤„ç† ACDC æ•°æ®é›†...")
    stats = preprocessor.batch_preprocess_acdc()
    
    logger.info(f"âœ… ACDC é¢„å¤„ç†å®Œæˆ:")
    logger.info(f"   æ€»æ–‡ä»¶: {stats['total_files']}")
    logger.info(f"   å¤„ç†æ–‡ä»¶: {stats['processed_files']}")
    logger.info(f"   è·³è¿‡æ–‡ä»¶: {stats['skipped_files']}")
    logger.info(f"   é”™è¯¯: {stats['errors']}")
    
    return stats


def main():
    parser = argparse.ArgumentParser(description='ä¸€æ¬¡æ€§é¢„å¤„ç†æ•°æ®é›†æ ‡ç­¾')
    parser.add_argument('--cityscapes-root', type=str, 
                       default='/root/projects/mmseg/datasets/cityscapes',
                       help='Cityscapes æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--acdc-root', type=str,
                       default='/root/projects/mmseg/datasets/acdc', 
                       help='ACDC æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--force', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°é¢„å¤„ç†')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¼€å§‹ä¸€æ¬¡æ€§æ•°æ®é¢„å¤„ç†...")
    
    # é¢„å¤„ç† Cityscapes
    if Path(args.cityscapes_root).exists():
        preprocess_cityscapes(Path(args.cityscapes_root), args.force)
    else:
        logger.warning(f"âš  Cityscapes è·¯å¾„ä¸å­˜åœ¨: {args.cityscapes_root}")
    
    # é¢„å¤„ç† ACDC  
    if Path(args.acdc_root).exists():
        preprocess_acdc(Path(args.acdc_root), args.force)
    else:
        logger.warning(f"âš  ACDC è·¯å¾„ä¸å­˜åœ¨: {args.acdc_root}")
    
    logger.info("âœ… æ‰€æœ‰æ•°æ®é¢„å¤„ç†å®Œæˆï¼")


if __name__ == '__main__':
    main()